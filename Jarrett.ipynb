{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T06:19:25.254729Z",
     "start_time": "2024-06-20T06:19:25.145772Z"
    }
   },
   "source": [
    "#########################################\n",
    "# Test functions and non-permanent code #\n",
    "# Author: Jarrett Reimers               #\n",
    "\n",
    "# Keep as a reference, do not edit      #\n",
    "#########################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import copy\n",
    "\n",
    "import query\n",
    "from model import Model\n",
    "import parameter\n",
    "import plotly.express as px\n",
    "import simplejson, urllib\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "\n",
    "if not os.path.exists(\"images\"):\n",
    "    os.mkdir(\"images\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T15:08:20.325780Z",
     "start_time": "2024-06-27T15:08:20.305165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test = {'a': 1, 'b': 2, 'c': 3}\n",
    "t = np.array(test.values())\n",
    "print(test)"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m test \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ma\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m1\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m2\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mc\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m3\u001B[39m}\n\u001B[0;32m----> 2\u001B[0m t \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241m.\u001B[39marray(test\u001B[38;5;241m.\u001B[39mvalues())\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(test)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'np' is not defined"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T15:08:27.983874Z",
     "start_time": "2024-06-27T15:08:27.980436Z"
    }
   },
   "cell_type": "code",
   "source": "print('yes')",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print('test')"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T19:16:31.608410Z",
     "start_time": "2024-06-18T19:16:31.359405Z"
    }
   },
   "cell_type": "code",
   "source": [
    "stations = pd.read_csv('data/stations.csv', index_col=0)\n",
    "tph = 4\n",
    "path = f'data/station_data/test_whitelist/v1/tph_{tph}/'\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "    \n",
    "station_information = pd.read_csv('data/station_data/status_at_time/2024_6_18_10:4.csv', index_col=0)\n",
    "\n",
    "\n",
    "whitelist = ['Allen St & Rivington St', 'Allen St & Stanton St', '1 Ave & E 16 St', 'Mercer St & Spring St', 'Mercer St & Bleecker St', '9 Ave & W 18 St', 'E 103 St & Lexington Ave', '1 Ave & E 6 St', 'Norfolk St & Broome St', 'E 1 St & 1 Ave', 'S 4 St & Wythe Ave', 'Lafayette St & Jersey St', 'Broadway & Berry St', 'S 5 Pl & S 5 St', 'E 5 St & Cooper Sq', 'Howard St & Lafayette St', 'E 32 St & Park Ave', 'Greenwich St & Hubert St', 'W 27 St & 7 Ave', 'Vesey Pl & River Terrace']\n",
    "\n",
    "\n",
    "station_list = {}\n",
    "start_date = query.get_datetime(2024, 5, 1, 0, 0, 0)\n",
    "end_date = query.get_datetime(2024, 5, 30, 0, 0, 0)\n",
    "\n",
    "        \n",
    "station_list1 = {}\n",
    "path1 = f'data/station_data/test_whitelist/v1/'\n",
    "tph = 12\n",
    "for station in whitelist:\n",
    "    station_list1[station] = parameter.get_pickle_station(station, path1)\n",
    "    station_list1[station].refine_by_3()\n",
    "station_list0 = copy.deepcopy(station_list1)\n",
    "station_list2 = copy.deepcopy(station_list1)\n",
    "model_0 = Model(station_names=whitelist, stations_dict=station_list0, in_transit=[], tph=tph)\n",
    "model_0.init_state(path='data/station_data/status_at_time/2024_6_17_14:6.csv', time=timedelta(hours=14))\n",
    "model_1 = Model(station_names=whitelist, stations_dict=station_list1, in_transit=[], tph=tph)\n",
    "model_1.init_state(path='data/station_data/status_at_time/2024_6_17_14:6.csv', time=timedelta(hours=14))\n",
    "model_2 = Model(station_names=whitelist, stations_dict=station_list2, in_transit=[], tph=tph)\n",
    "model_2.init_state(path='data/station_data/status_at_time/2024_6_17_15:5.csv', time=timedelta(hours=15))\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T19:16:31.614732Z",
     "start_time": "2024-06-18T19:16:31.611098Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_1.cluster_stations(0.005)\n",
    "print(model_1.clusters)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 horizontal squares and 13 vertical squares. Total squares: 195\n",
      "[['Vesey Pl & River Terrace'], [], [], [], [], [], [], [], [], [], [], [], [], [], [], ['Greenwich St & Hubert St'], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], ['9 Ave & W 18 St'], [], [], [], [], [], [], [], ['Howard St & Lafayette St'], ['Mercer St & Spring St'], ['Mercer St & Bleecker St'], [], [], [], [], [], [], [], [], [], [], [], ['Lafayette St & Jersey St'], [], [], [], [], ['W 27 St & 7 Ave'], [], [], [], [], [], [], ['Allen St & Rivington St', 'Norfolk St & Broome St'], ['Allen St & Stanton St', 'E 1 St & 1 Ave'], ['E 5 St & Cooper Sq'], [], [], [], [], [], [], [], [], [], [], [], [], ['1 Ave & E 6 St'], ['1 Ave & E 16 St'], [], [], ['E 32 St & Park Ave'], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], ['S 4 St & Wythe Ave', 'Broadway & Berry St'], [], [], [], [], [], [], [], [], [], [], [], [], ['S 5 Pl & S 5 St'], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], ['E 103 St & Lexington Ave'], [], [], [], [], [], [], [], [], [], []]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T19:49:20.905899Z",
     "start_time": "2024-06-17T19:49:20.649184Z"
    }
   },
   "cell_type": "code",
   "source": [
    "station_information = simplejson.load(\n",
    "        urllib.request.urlopen('https://gbfs.lyft.com/gbfs/2.3/bkn/en/station_information.json'))\n",
    "station_status = simplejson.load(\n",
    "        urllib.request.urlopen('https://gbfs.lyft.com/gbfs/2.3/bkn/en/station_status.json'))\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T19:49:58.943800Z",
     "start_time": "2024-06-17T19:49:58.938594Z"
    }
   },
   "cell_type": "code",
   "source": "station_status['data']['stations'][67]",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vehicle_types_available': [{'vehicle_type_id': '1', 'count': 4},\n",
       "  {'vehicle_type_id': '2', 'count': 1}],\n",
       " 'num_scooters_unavailable': 0,\n",
       " 'num_bikes_disabled': 3,\n",
       " 'num_bikes_available': 4,\n",
       " 'station_id': '6fb81fda-f0b5-4242-90f9-88d0214feb8d',\n",
       " 'is_returning': 1,\n",
       " 'is_renting': 1,\n",
       " 'num_docks_available': 11,\n",
       " 'num_docks_disabled': 0,\n",
       " 'last_reported': 1718653652,\n",
       " 'num_ebikes_available': 0,\n",
       " 'num_scooters_available': 0,\n",
       " 'is_installed': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T19:29:32.254278Z",
     "start_time": "2024-06-12T19:29:31.959032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_date = query.get_datetime(2023, 5, 1, 0, 0, 0)\n",
    "end_date = query.get_datetime(2023, 5, 30, 0, 0, 0)\n",
    "whitelist_stations = ['E 7 St & Ave B',\n",
    "                      'Cooper Square & Astor Pl',\n",
    "                      'E 7 St & Ave C',\n",
    "                      'Ave A & E 14 St',\n",
    "                      'W 21 St & 6 Ave']\n",
    "\n",
    "parameter.avg_travel_time(whitelist_stations[0], whitelist_stations[1], start_date, end_date)\n",
    "# parameter.get_transition('W 21 St & 6 Ave', start_date=start_date, end_date=end_date, tph=1)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timedelta('0 days 00:07:10.272317403')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T15:53:38.556345Z",
     "start_time": "2024-06-13T15:53:38.551711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tph = 2\n",
    "date = datetime.timedelta(hours=0.1)\n",
    "date"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(seconds=360)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "start_date = query.get_datetime(2023, 5, 1, 0, 0, 0)\n",
    "end_date = query.get_datetime(2023, 6, 30, 0, 0, 0)\n",
    "parameter.get_rate('2 Ave & E 29 St',start_date=start_date, end_date=end_date, length=datetime.timedelta(hours=1), weekday=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T19:11:21.437494Z",
     "start_time": "2024-06-12T19:11:19.347043Z"
    }
   },
   "source": [
    "data = pd.read_csv(\"data/2023/by_station/Cooper Square & Astor Pl.csv\", low_memory=False, index_col=0)\n",
    "data = query.make_datetime(data)\n",
    "stations = data['end_station_name'].unique()\n",
    "good_stations = []\n",
    "for station in stations:\n",
    "    num = len(data.loc[data['end_station_name'] == station])\n",
    "    if num/len(data) > 0.008:\n",
    "        good_stations.append(station)\n",
    "print(good_stations)"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "station_list = query.get_stations(data)\n",
    "station_id = 324 \n",
    "station_data = query.select_start_station(data, station_id)\n",
    "stations = Model()\n",
    "start_time = query.get_datetime(2015, 5, 1, 0, 0, 0)\n",
    "\n",
    "freq = []\n",
    "for day in range(0, 60):\n",
    "  stations.clear_data()\n",
    "  window = datetime.timedelta(days=1)\n",
    "  end_time = start_time + window\n",
    "  window_data = query.select_time(station_data, start_time, end_time)\n",
    "  stations.add_data(window_data)\n",
    "\n",
    "  # print(\"Total trips started on day\", day)\n",
    "  # if station_id in stations.stations_count:\n",
    "  #   print(stations.stations_count[station_id])\n",
    "  # else:\n",
    "  #   print(0)\n",
    "  \n",
    "  daily = []\n",
    "  for hour in range(0, 24):\n",
    "    stations.clear_data()\n",
    "    window = datetime.timedelta(hours=1)\n",
    "    end_time = start_time + window\n",
    "    window_data = query.select_time(station_data, start_time, end_time)\n",
    "    stations.add_data(window_data)\n",
    "\n",
    "    if station_id in stations.stations_count:\n",
    "      # print(hour, stations.stations_count[station_id])\n",
    "      daily.append(stations.stations_count[station_id])\n",
    "    else:\n",
    "      # print(hour, 0)\n",
    "      daily.append(0)\n",
    "      \n",
    "    start_time = end_time\n",
    "  freq.append(daily)\n",
    "  start_time = end_time\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "start_time = query.get_datetime(2023, 4, 1, 0, 0, 0)\n",
    "end_time = query.get_datetime(2023, 7, 1, 0, 0, 0)\n",
    "interval = 0.5\n",
    "\n",
    "freqs = []\n",
    "while start_time < end_time:\n",
    "    freq = []\n",
    "    if start_time.weekday() > 5:\n",
    "        start_time += datetime.timedelta(days=1)\n",
    "        continue\n",
    "    daily_rides = len(query.select_time(data, start_time, start_time+datetime.timedelta(days=1)))\n",
    "    if daily_rides < 150 or daily_rides > 250:\n",
    "        start_time += datetime.timedelta(days=1)\n",
    "        continue   \n",
    "    for hour in range(int(24/interval)):\n",
    "        stop_time = start_time + datetime.timedelta(hours=interval)\n",
    "        rides = len(query.select_time(data, start_time, stop_time))\n",
    "        freq.append(rides)\n",
    "        start_time = stop_time\n",
    "    freqs.append(freq)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = pd.DataFrame(freqs)\n",
    "# p = 0.73\n",
    "plt.plot(df.var() - df.mean())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "p = 0.73295\n",
    "(df.var() - df.mean()/p).sum()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "col = 27\n",
    "plt.hist(df[col].T, bins=df[col].T.max())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plt.hist(df.T.sum(), bins=30)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for q in df.quantile(0.1):\n",
    "    trimmed_df = df.loc[df[col] > q]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# stations = Stations()\n",
    "# stations.add_data(query.select_time(data, start_time, end_time))\n",
    "#   \n",
    "# pyplot.plot(range(len(stations.stations_count)), stations.stations_count.values())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "maximum = 0\n",
    "max_station = 0\n",
    "for station in stations.stations_count:\n",
    "  if stations.stations_count[station] > maximum:\n",
    "    max_station = station\n",
    "    maximum = stations.stations_count[station]\n",
    "print(\"The maximum is at station:\", max_station, \". With\", maximum, \"bikes at end of period\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "minimum = 0\n",
    "min_station = 0\n",
    "for station in stations.stations_count:\n",
    "  if stations.stations_count[station] < minimum:\n",
    "    min_station = station\n",
    "    minimum = stations.stations_count[station]\n",
    "print(\"The minimum is at station:\", min_station, \". With\", minimum, \"bikes at end of period\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "windows = [0.25, 0.5, 1]\n",
    "\n",
    "start_time = query.get_datetime(2015, 5, 1, 0, 0, 0)\n",
    "stop_time = query.get_datetime(2015, 5, 31, 0, 0, 0)\n",
    "weekdays_and_ends = parameter.get_weekdays_and_weekends(start_time, stop_time)\n",
    "weekdays = weekdays_and_ends[0]\n",
    "weekends = weekdays_and_ends[1]\n",
    "stations = (data['start station id']).unique()\n",
    "\n",
    "daily_trips = []\n",
    "for start_time in weekdays:\n",
    "  end_time = start_time + datetime.timedelta(days=1)\n",
    "  daily_trips.append(len(query.select_time(data, start_time, end_time)))\n",
    "  start_time += datetime.timedelta(days=1)\n",
    "# throughput = pd.cut(daily_trips, 3, labels=range(3))\n",
    "\n",
    "for hours in windows:\n",
    "  # for station_id in stations[:5]:\n",
    "    weekday_freqs = [] \n",
    "    station_id = 537\n",
    "    station_df = query.select_start_station(data, station_id)\n",
    "    \n",
    "    for start_time in weekdays:\n",
    "      freq = []\n",
    "      stop_time = start_time+datetime.timedelta(days=1)\n",
    "      time_df = query.select_time(station_df, start_time, stop_time).reset_index(drop=True)\n",
    "      chop_df = parameter.cut(time_df, start_time, stop_time, datetime.timedelta(hours=hours))\n",
    "      for i in range(len(chop_df)):\n",
    "        freq.append(len(chop_df[i]))\n",
    "      weekday_freqs.append(freq)\n",
    "    \n",
    "    rows = []\n",
    "    i = 0\n",
    "    for daily in weekday_freqs:\n",
    "      hour = 0\n",
    "      for hourly in daily:\n",
    "        rows.append([hourly, hour, daily_trips[i]])\n",
    "        hour += 1\n",
    "      i+=1 \n",
    "    df = pd.DataFrame(rows, columns=['trips', 'hours', 'Total throughput'])\n",
    "    \n",
    "    trip_data = pd.DataFrame(weekday_freqs)\n",
    "    rate = trip_data.sum()/len(trip_data.T.iloc[0])\n",
    "    pred = np.random.poisson(rate)\n",
    "    \n",
    "    fig = px.scatter(df, x='hours', y='trips', color='Total throughput', template='plotly',\n",
    "                     width=1200, height=500, labels={'hours': 'Half-hours', 'trips': 'Departures', 'Total throughput': 'Total throughput'}, title=\"Daily departure breakdown (May, weekday only)\")\n",
    "    fig.add_trace(go.Scatter(x=np.array(range(int(24/hours))), y=np.array(pred),\n",
    "                        mode='lines',\n",
    "                        name=''))\n",
    "    \n",
    "    if not os.path.exists(f\"images/{station_id}/\"):\n",
    "      os.mkdir(f\"images/{station_id}/\")\n",
    "    fig.write_image(f'images/{station_id}/{hours}_test.png')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "station_data = query.select_start_station(data, 537)\n",
    "start_time = query.get_datetime(2015, 5, 1, 0, 0, 0)\n",
    "end_time = query.get_datetime(2015, 5, 31, 0, 0, 0)\n",
    "\n",
    "slide_data = []\n",
    "while start_time <= end_time:\n",
    "    stop_time = start_time+datetime.timedelta(days=1)\n",
    "    time_df = query.select_time(station_data, start_time, stop_time).reset_index(drop=True)\n",
    "    slide_data.append(len(time_df))\n",
    "    start_time = stop_time\n",
    "    "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "start_time = query.get_datetime(2015, 5, 1, 0, 0, 0)\n",
    "end_time = query.get_datetime(2015, 5, 31, 0, 0, 0)\n",
    "station_data = query.select_time(data, start_time, end_time).reset_index(drop=True)\n",
    "weekdays_and_ends = parameter.get_weekdays_and_weekends(start_time, end_time)\n",
    "weekdays = weekdays_and_ends[0]\n",
    "slide_freqs = [] \n",
    "\n",
    "for start_time in weekdays:\n",
    "    freq = []\n",
    "    stop_time = start_time+datetime.timedelta(days=1)\n",
    "    time_df = query.select_time(station_data, start_time, stop_time).reset_index(drop=True)\n",
    "    chop_df = parameter.cut(time_df, start_time, stop_time, datetime.timedelta(hours=0.5))\n",
    "    for i in range(len(chop_df)):\n",
    "      freq.append(len(chop_df[i]))\n",
    "    slide_freqs.append(freq)\n",
    "slide_freqs = pd.DataFrame(slide_freqs)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "path = 'data/2023/by_station/'\n",
    "for file in os.listdir(path)[::20]:\n",
    "    data = pd.read_csv(path+file)\n",
    "    data = query.make_datetime(data)\n",
    "    start_time = query.get_datetime(2023, 5, 1, 0, 0, 0)\n",
    "    end_time = query.get_datetime(2023, 9, 30, 0, 0, 0)\n",
    "    station_data = query.select_time(data, start_time, end_time)\n",
    "    weekdays_and_ends = parameter.get_weekdays_and_weekends(start_time, end_time)\n",
    "    weekdays = weekdays_and_ends[0]\n",
    "    freq = []\n",
    "    hour = 17\n",
    "    window = 2\n",
    "    \n",
    "    for day in weekdays:\n",
    "        start_time = day + datetime.timedelta(hours=hour)\n",
    "        stop_time = start_time + datetime.timedelta(hours=window)\n",
    "        time_df = query.select_time(station_data, start_time, stop_time).reset_index(drop=True)\n",
    "        freq.append(len(time_df))\n",
    "        \n",
    "    df = pd.DataFrame(freq)\n",
    "    if df[0].max() == 0:\n",
    "        print(\"No departures for\", file)\n",
    "        continue\n",
    "    plt.hist(df[0], bins=int(df[0].max()))        \n",
    "    plt.savefig(f'images/histograms/{file[:-4]}.png')\n",
    "    plt.close()\n",
    "    "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "start_date = query.get_datetime(2023, 5, 1, 0, 0, 0)\n",
    "end_date = query.get_datetime(2023, 6, 30, 0, 0, 0)\n",
    "parameter.get_rate('2 Ave & E 29 St',start_date=start_date, end_date=end_date, length=datetime.timedelta(hours=1))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T19:11:36.113511Z",
     "start_time": "2024-06-12T19:11:31.129469Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4 Ave & E 12 St', '1 Ave & E 6 St', 'E 7 St & Ave B', 'Cooper Square & Astor Pl', 'St Marks Pl & 1 Ave', 'E 5 St & Ave A', 'E 7 St & Ave C', 'E 5 St & Avenue C', 'E 4 St & Ave B', 'E 7 St & Avenue A', 'E 17 St & Broadway', 'Ave A & E 14 St', 'Broadway & E 14 St', 'E 6 St & Avenue B', 'E 6 St & 2 Ave', 'W 21 St & 6 Ave']\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data = pd.read_csv('data/2023/by_station/Riverside Dr & W 78 St.csv', low_memory=False, index_col=0)\n",
    "data.dropna(axis=\"rows\", inplace=True)\n",
    "data = query.make_datetime(data)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "start_time = query.get_datetime(2023, 5, 1, 0, 0, 0)\n",
    "end_time = query.get_datetime(2023, 8, 30, 0, 0, 0)\n",
    "length = datetime.timedelta(hours=1)\n",
    "\n",
    "whitelist_stations = ['4 Ave & E 12 St',\n",
    " '1 Ave & E 6 St',\n",
    " 'E 7 St & Ave B',\n",
    " 'Cooper Square & Astor Pl',\n",
    " 'St Marks Pl & 1 Ave',\n",
    " 'E 5 St & Ave A',\n",
    " 'E 7 St & Ave C',\n",
    " 'E 4 St & Ave B',\n",
    " 'E 7 St & Avenue A',\n",
    " 'Ave A & E 14 St']\n",
    "\n",
    "cut_df = query.select_time(data, start_time, end_time)\n",
    "stations_transition_by_hour = {hour: {} for hour in range(24)}\n",
    "trip_count = {i: 0 for i in range(24)}\n",
    "\n",
    "weekdays = parameter.get_weekdays_and_weekends(start_time, end_time)[0]\n",
    "total_unique_stations = len(cut_df['end_station_name'].unique())\n",
    "for day in weekdays:\n",
    "    end_time = day + datetime.timedelta(days=1)\n",
    "    cut_list = parameter.cut(cut_df, day, end_time, length)\n",
    "    for i in range(len(cut_list)):\n",
    "        total_trips = 0\n",
    "        for station in cut_list[i]['end_station_name'].unique():\n",
    "            if station not in whitelist_stations:\n",
    "                continue\n",
    "            station_trips = len(cut_list[i].loc[cut_list[i]['end_station_name'] == station])\n",
    "            total_trips += station_trips\n",
    "            if station in stations_transition_by_hour[i]:\n",
    "                stations_transition_by_hour[i][station] += station_trips\n",
    "            else:\n",
    "                stations_transition_by_hour[i][station] = station_trips\n",
    "        trip_count[i] += total_trips"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "transitions = []\n",
    "total_total = 0\n",
    "\n",
    "total_low = 0\n",
    "total_mid = 0   \n",
    "total_high = 0\n",
    "\n",
    "total_num_low = 0\n",
    "total_num_mid = 0\n",
    "total_num_high = 0\n",
    "\n",
    "for hour in stations_transition_by_hour:\n",
    "    num_stations = len(stations_transition_by_hour[hour])\n",
    "    total_hour = 0\n",
    "    \n",
    "    hour_low = 0\n",
    "    hour_mid = 0   \n",
    "    hour_high = 0\n",
    "    \n",
    "    num_low = 0\n",
    "    num_mid = 0\n",
    "    num_high = 0\n",
    "    \n",
    "    num_unique_stations = len(stations_transition_by_hour[hour])\n",
    "    for station in stations_transition_by_hour[hour]:\n",
    "        num = stations_transition_by_hour[hour][station]\n",
    "        total_hour += num\n",
    "        if  num/trip_count[hour] < 1/(3*num_unique_stations):\n",
    "            num_low +=1\n",
    "            hour_low += num\n",
    "        elif num/trip_count[hour] < 1/(2*num_unique_stations):\n",
    "            num_mid +=1\n",
    "            hour_mid += num\n",
    "        else:\n",
    "            num_high += 1\n",
    "            hour_high += num\n",
    "    if total_hour == 0:\n",
    "        print(f'No trips detected in {hour}')\n",
    "        continue\n",
    "    print(f'In hour: {hour} there was {total_hour} observations and {num_unique_stations} unique stations')\n",
    "    print(f'Low: {num_low} stations, Mid: {num_mid} stations, High: {num_high} stations')\n",
    "    print(f'Low: {hour_low/total_hour}, Mid: {hour_mid/total_hour}, High: {hour_high/total_hour}')\n",
    "    print()\n",
    "    \n",
    "    total_total += total_hour\n",
    "    \n",
    "    total_low += hour_low\n",
    "    total_mid += hour_mid\n",
    "    total_high += hour_high\n",
    "    \n",
    "    total_num_low += num_low\n",
    "    total_num_mid += num_mid\n",
    "    total_num_high += num_high\n",
    "\n",
    "print()\n",
    "print(f'Over the entire period: {start_time} to {end_time} there was {total_total} observations and {total_unique_stations} total unique stations')\n",
    "print(f'Low: {total_low/total_total}, Mid: {total_mid/total_total}, High: {total_high/total_total}') "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "\n",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "transitions",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
